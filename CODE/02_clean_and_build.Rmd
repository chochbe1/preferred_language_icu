
# Setup Step: Setup libraries
```{r}
# Load necessary libraries
library(data.table)
library(dplyr)
library(zoo)  # for na.locf function
library(lubridate)
library(tidyr)
library(fst)
library(arrow)
library(table1)
library(metafor)
library(yaml)
library(here)

config <- yaml::read_yaml(here("config.yaml"))

# Define directories based on YAML configuration
data_dir <- config$data_dir
output_dir <- file.path(data_dir, "sedation_language_project/intermediate_data/")  # Define output_dir based on data_dir
file_type <- config$file_type
institution <- config$institution


# Create the output directory if it does not exist
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)  # 'recursive = TRUE' allows creating nested directories
}
```

# PART ONE:
# ***Define directories for the rest of the script
# ***Upload Necessary Tables

```{r}
read_data <- function(file_path, select = NULL) {
  if (grepl("\\.csv$|\\.csv\\.gz$", file_path)) {
    # Use fread with the select argument for CSV and CSV.GZ files
    return(fread(file_path, select = all_of(select)))
  } else if (grepl("\\.parquet$", file_path)) {
    # Use read_parquet with col_select for Parquet files
    return(arrow::read_parquet(file_path, col_select = all_of(select)))
  } else if (grepl("\\.fst$", file_path)) {
    # Use read_fst with columns for FST files
    return(fst::read_fst(file_path, columns = all_of(select)))
  } else {
    stop("Unsupported file format. Only CSV, Parquet, and FST are supported.")
  }
}

# Upload Part One Data Table
part_one_data <- fread(file.path(output_dir, "imv_runs.csv.gz"))
part_one_hosp_id <- unique(part_one_data$hospitalization_id)

# STEP 1: Load Patient Assessments For Hospitalization_IDs above
specific_assessment_categories <- c("RASS", "gcs_total")
patient_assessments <- as.data.table(read_data(file.path(data_dir, paste0("clif_patient_assessments", file_type)), 
                             select = c("hospitalization_id", "recorded_dttm", "assessment_category", "numerical_value")))[
                               hospitalization_id %in% part_one_hosp_id & assessment_category %in% specific_assessment_categories]


# STEP 2: Upload CLIF Vitals 
specific_vital_categories <- c("sbp", "dbp", "height_cm", "weight_kg")
vitals <- as.data.table(read_data(file.path(data_dir, paste0("clif_vitals", file_type)), 
  select = c("hospitalization_id", "recorded_dttm", "vital_category", "vital_value"))
)[hospitalization_id %in% part_one_hosp_id & vital_category %in% specific_vital_categories]



# STEP 3: Upload CLIF Labs
# Labs Table Conversion to recorded_dttm
# Using Lab Collect DTTM as the marker instead of order or result
specific_lab_categories <- c("creatinine", "bilirubin_total", "platelet_count", "po2_arterial")
labs <- as.data.table(read_data(file.path(data_dir, paste0("clif_labs", file_type)), 
                                select = c("hospitalization_id", "lab_collect_dttm", "lab_category", "lab_value_numeric")))[
  hospitalization_id %in% part_one_hosp_id & lab_category %in% specific_lab_categories]
setorder(labs, hospitalization_id, lab_collect_dttm)
setnames(labs, "lab_collect_dttm", "recorded_dttm")
labs[, recorded_dttm := as.POSIXct(recorded_dttm, origin = "1970-01-01")]


# STEP 4: Upload CLIF Continuous Meds
# Upload CLIF Continuous Meds
meds <- as.data.table(read_data(file.path(data_dir,paste0("clif_medication_admin_continuous", file_type)), select = c("hospitalization_id", "admin_dttm", "med_dose", "med_dose_unit", "med_category", "med_group")))[hospitalization_id %in% part_one_hosp_id]


# STEP 5: Upload CLIF ADT Table
adt <- as.data.table(read_data(file.path(data_dir,paste0("clif_adt", file_type)), select = c("hospitalization_id", "hospital_id", "in_dttm", "out_dttm")))[hospitalization_id %in% part_one_hosp_id]


# STEP 6: Upload CLIF Hospitalization Table
hospitalization <- as.data.table(read_data(file.path(data_dir,paste0( "clif_hospitalization", file_type)), select = c("patient_id", "hospitalization_id", "admission_dttm", "age_at_admission")))[hospitalization_id %in% part_one_hosp_id]
hospitalization <- unique(hospitalization, by = "hospitalization_id")
pat_imv_part_two <- unique(hospitalization$patient_id)


# STEP 7: Upload CLIF Patient Table
patient <- as.data.table(read_data(file.path(data_dir,paste0("clif_patient", file_type)), select = c("patient_id", "sex_category", "race_category", "ethnicity_category", "language_name", "death_dttm")))[patient_id %in% pat_imv_part_two]


# STEP 8: Upload CLIF Respiratory Support
respiratory_support <- as.data.table(read_data(file.path(data_dir,paste0( "clif_respiratory_support", file_type)), select = c("hospitalization_id", "recorded_dttm", "fio2_set")))[hospitalization_id %in% part_one_hosp_id]
```


# PART TWO: Filter out hospitalizations with RASS issues
# ***Identify earliest RASS timepoint
# ***Flag hospitalizations with missing RASS values between 2 hours before and 8 hours after IMV
```{r}
# STEP 1: Form RASS Specific Patient Assessment Table
pat_assess_rass <- patient_assessments[assessment_category == "RASS"]
setorder(pat_assess_rass, hospitalization_id, recorded_dttm)

part_one_data <- part_one_data %>%
  mutate(hospitalization_id = as.character(hospitalization_id))

pat_assess_rass <- pat_assess_rass %>%
  mutate(hospitalization_id = as.character(hospitalization_id))

# STEP 2: Merge part_one_data with RASS
hosp_time_rass <- merge(part_one_data, pat_assess_rass, by = "hospitalization_id", all = TRUE)


# STEP 3: Identify first RASS Timepoint
pat_first_rass <- hosp_time_rass[!is.na(begin_imv), 
                                  .(first_rass_dttm = if (all(is.na(recorded_dttm[recorded_dttm >= begin_imv]))) 
                                                       as.POSIXct(NA) 
                                                     else 
                                                       min(recorded_dttm[recorded_dttm >= begin_imv], na.rm = TRUE)), 
                                  by = hospitalization_id]

# STEP 4: Merge Again
hosp_first_rass <- merge(part_one_data, pat_first_rass, by = "hospitalization_id", all = TRUE)

# STEP 4: Calculate time between first RASS and beginning mechanical ventilation
hosp_first_rass[, time_to_first_rass := as.numeric(difftime(first_rass_dttm, begin_imv, units = "hours"))]


# STEP 5: Filter Out Hospitalizations with >8 hours or more gap between begin IMV and first RASS as well as those with no RASS values
hosp_rass_clean <- hosp_first_rass[!is.na(time_to_first_rass) & time_to_first_rass <= 8]

hosp_id_rass_clean <- unique(hosp_rass_clean$hospitalization_id)

patient_assessments %>% count(assessment_category)
```


# PART THREE: Filter out hospitalizations with missing vitals information
# *** Calculate BMI
# *** Filter out hospitalizations without BMI data
```{r}

# STEP 1: Create weight / height vitals only table
vitals_weight_height <- vitals[vital_category %in% c("weight_kg", "height_cm")][hospitalization_id %in% hosp_id_rass_clean]


# STEP 2: Reshape the data to put weight into separate columns, using 'mean' to handle duplicates
vitals_weight_height <- dcast(vitals_weight_height, 
                   hospitalization_id + recorded_dttm ~ vital_category, 
                   value.var = "vital_value", 
                   fun.aggregate = mean,  # Aggregate duplicates using mean
                   fill = NA)  # Fill missing values with NA
vitals_weight_height <- vitals_weight_height[, .(hospitalization_id, recorded_dttm, weight_kg, height_cm)]
setorder(vitals_weight_height, hospitalization_id, recorded_dttm)


# STEP 3: Filter Out improbably low weights and select first weight
admission_weights <- vitals_weight_height[
  weight_kg >= 35,  # Filter out extreme values
  .(admission_weight = weight_kg[1]),  # Select the first weight for each group
  by = hospitalization_id
]

# STEP 4: Filter Out Improbably low heights and select first height
admission_heights <- vitals_weight_height[
  height_cm >= 100,  # Filter out extreme values
  .(admission_height = height_cm[1]),  # Select the first height for each group
  by = hospitalization_id
]

# STEP 5: Calculate BMI
admission_bmi <- merge(admission_weights, admission_heights, by = "hospitalization_id", all = TRUE)
admission_bmi[, height_m := admission_height / 100]
admission_bmi[, bmi := admission_weight / (height_m^2)]

admission_bmi <- admission_bmi[!is.na(bmi) & bmi != ""]
admission_bmi_final <- admission_bmi[bmi >= 12 & bmi <= 100]
admission_bmi_final <- admission_bmi_final[, .(hospitalization_id, bmi)]

hosp_id_vitals_clean <- unique(admission_bmi_final$hospitalization_id)
```



# PART FOUR: Define Clean Tables
# ***Clean part one data for only hospital ids that made it through cleaning in PART TWO and PART THREE
# ***Establish timeline for each hospitalization_id around their IMV times
```{r}
# STEP 1: Clean Part One Data so it only has hospitalization_ids identified after cleaning steps
part_one_data_clean <- part_one_data[hospitalization_id %in% hosp_id_vitals_clean]



# STEP 2: Expand table to create 15-min increments from 24 hours before mechanical ventilation to 48 hours after mechanical ventilation for all hospitalization_ids
hosp_clean_timeline <- part_one_data_clean[, .(recorded_dttm = seq(
                                          from = as.POSIXct(min(begin_imv)) - hours(24), 
                                          to = as.POSIXct(min(begin_imv) + hours(48)),
                                          by = "15 min")), 
                                  by = .(hospitalization_id)]
```


# PART FIVE: Build RASS Percentage Table
# ***Use LOCF Logic to fill out RASS scores for the first 48 hours of mechanical ventilation
# ***Calculate the precent time spent in deep sedation (defined as a RASS score less than or equal to -3)
```{r}
# STEP 1: Filter previous RASS table only for those with clean hospitalization ids
pat_assess_rass_clean <- pat_assess_rass[hospitalization_id %in% hosp_id_vitals_clean]
setorder(pat_assess_rass_clean, hospitalization_id, recorded_dttm)

# Remove '+' symbols and convert 'numerical_value' to numeric
pat_assess_rass_clean[, numerical_value := as.numeric(gsub("\\+", "", numerical_value))]


# STEP 2: Reshape the data from long to wide
pat_assess_rass_clean <- dcast(
    pat_assess_rass_clean, 
    hospitalization_id + recorded_dttm ~ assessment_category, 
    value.var = "numerical_value", 
    fun.aggregate = function(x) mean(x, na.rm = TRUE),  # Aggregate with NA handling
    fill = NA
)
pat_assess_rass_clean <- pat_assess_rass_clean[, .(hospitalization_id, recorded_dttm, RASS)]


# Convert recorded_dttm in pat_assess_rass_clean to POSIXct
pat_assess_rass_clean[, recorded_dttm := as.POSIXct(recorded_dttm, format = "%Y-%m-%dT%H:%M:%OSZ", tz = "UTC")]


# STEP 3: Merge with Timeline to give additional data points for filling
rass_timeline <- merge(hosp_clean_timeline, pat_assess_rass_clean, by = c("hospitalization_id", "recorded_dttm"), 
                         all = TRUE)

# STEP 4: Merge Clean Part One Data with RASS
rass_timeline_clean <- merge(part_one_data_clean, rass_timeline, by = "hospitalization_id", all = TRUE)


# STEP 5: Use LOCF to fill in missing RASS Data
rass_timeline_clean[RASS == "", RASS := NA]
rass_timeline_clean[, RASS := na.locf(RASS, na.rm = FALSE), by = hospitalization_id]


# STEP 6: Filter only for values between begin_imv and 48 hours after IMV (or if extubated/expired before 48 hours then however long they were ventilated for)
# Calculate start_time
rass_timeline_clean[, start_time := as.POSIXct(begin_imv), by = hospitalization_id]

# Calculate end_time based on the condition for each hospitalization_id
rass_timeline_clean[, end_time := ifelse(total_imv_time >= 48, 
                                         as.POSIXct(begin_imv) + hours(48),  
                                         as.POSIXct(end_imv)), 
                     by = hospitalization_id]

# Filter the table to retain rows where recorded_dttm is within the time range
rass_hosp_filt <- rass_timeline_clean[recorded_dttm >= start_time & recorded_dttm <= end_time]

# Final filtered table with relevant columns
rass_hosp_final <- rass_hosp_filt[, .(hospitalization_id, recorded_dttm, begin_imv, RASS)]


# STEP 7: Flag patients with RASS scores of -3 or lower as deep sedation
rass_hosp_final[, deep_sedation := RASS <= -3]


# STEP 8: Calculate total time for each hospitalization_id
rass_hosp_final[, time_total := as.numeric(difftime(max(recorded_dttm), min(recorded_dttm), units = "hours")), 
               by = hospitalization_id]


# STEP 9: Calculate the time spent in deep sedation (deep_sedation == TRUE)
rass_hosp_final[, time_deep_sedation := sum(as.numeric(difftime(shift(recorded_dttm, type = "lead"), recorded_dttm, units = "hours")) * deep_sedation, na.rm = TRUE), 
               by = hospitalization_id]


# STEP 10: # Calculate the percent of time in deep sedation
rass_hosp_final[, percent_deep_sedation := (time_deep_sedation / time_total) * 100]


# STEP 11: Final Table
rass_percentages <- rass_hosp_final[, .(percent_deep_sedation = mean(percent_deep_sedation, na.rm = TRUE)), 
                                  by = hospitalization_id]
```


# PART SIX: Identify Paralyzed Patients
# ***Identify all patients receiving continuous paralytics within the first 48 hours of mechanical ventilation
```{r}
# STEP 1: Filter only for paralytic meds
meds_paralytics <- meds[med_group == "paralytics"]


# STEP 2: Filter only for doses >0
meds_paralytics_filtered <- meds_paralytics[med_dose > 0]


# STEP 3: Identify earliest admin_dttm for doses >0 for each hospitalization
earliest_paralytics <- meds_paralytics[, .(earliest_paralytic_dttm = min(admin_dttm)), by = hospitalization_id]


# STEP 4: Merge with clean part one data for filtering
paralytic_clean <- merge(part_one_data_clean, earliest_paralytics, by = "hospitalization_id", all.x = TRUE)


# STEP 5: Identify patients paralyzed within first 48 hours after beginning mechanical ventilation
paralytic_clean[, paralyzed := as.logical(abs(difftime(earliest_paralytic_dttm, begin_imv, units = "hours")) <= 48)]


# STEP 6: Fill Table Out and Choose Only hospitalization and paralytic data
paralytic_clean[, paralyzed := fifelse(is.na(paralyzed) | paralyzed == "", FALSE, paralyzed)]
paralytic_final <- paralytic_clean[, .(hospitalization_id, paralyzed)]
```


# PART SEVEN: Determine primary sedation medication used
# ***Identify the sedative infusion used for the majority of the first 48 hours of mechanical ventilation for each hospitalization_id
```{r}
# STEP 1: Filter only for sedative meds
meds_sedation <- meds[med_category %in% c("propofol", "dexmedetomidine", "ketamine", "midazolam", "pentobarbital", "lorazepam")][hospitalization_id %in% hosp_id_vitals_clean]


# STEP 2: Filter only for doses >0
meds_sedation_filtered <- meds_sedation[med_dose > 0]


# STEP 3: Merge with clean part one data for time filtering
meds_sedation_clean <- merge(part_one_data_clean, meds_sedation_filtered, by = "hospitalization_id", all.x = TRUE)


#STEP 4: TIME FILTERING
# Calculate start_time (24 hours before begin_imv)
meds_sedation_clean[, start_time := as.POSIXct(begin_imv), by = hospitalization_id]

# Calculate end_time based on the condition for each hospitalization_id
meds_sedation_clean[, end_time := as.POSIXct(begin_imv) + hours(48), by = hospitalization_id]

# Filter the table to retain rows where recorded_dttm is within the time range
meds_sedation_final <- meds_sedation_clean[admin_dttm >= start_time & admin_dttm <= end_time]
meds_sedation_final <- meds_sedation_final[, .(hospitalization_id, admin_dttm, med_category, med_dose, med_dose_unit)]
setnames(meds_sedation_final, "admin_dttm", "recorded_dttm")
setorder(meds_sedation_final, hospitalization_id, med_category, recorded_dttm)


# STEP 5: Set Up 48 hour Timeline for LOCF
timeline_48hrimv <- part_one_data_clean[, .(recorded_dttm = seq(
                                          from = as.POSIXct(min(begin_imv)) - hours(0), 
                                          to = as.POSIXct(min(begin_imv) + hours(48)),
                                          by = "15 min")), 
                                  by = .(hospitalization_id)]


# STEP 6: Merge Meds Sedation Final and Timeline
meds_sedation_timeline <- merge(timeline_48hrimv, meds_sedation_final, by = c("hospitalization_id", "recorded_dttm"), 
                         all = TRUE)


# STEP 7: Fill in Blanks and Use LOCF to Fill Out the Table
cols_to_update_meds <- c("med_category", "med_dose", "med_dose_unit")
meds_sedation_timeline[, (cols_to_update_meds) := lapply(.SD, function(x) fifelse(x == "", NA, x)), .SDcols = cols_to_update_meds]

#LOCF
meds_sedation_timeline_final <- meds_sedation_timeline[, (cols_to_update_meds) := lapply(.SD, function(x) na.locf(x, na.rm = FALSE)), 
                 by = hospitalization_id, .SDcols = cols_to_update_meds]


# STEP 8: Identify consecutive runs of the same med_category within each hospitalization_id
meds_sedation_timeline_final[, `:=`(
  run_id = rleid(med_category),  # Run ID for each consecutive block of the same med_category
  next_recorded_dttm = shift(recorded_dttm, type = "lead")  # Next recorded time
), by = hospitalization_id]


# STEP 9: Calculate duration of each run by finding the difference between the last and first recorded_dttm in each run
meds_sedation_timeline_final[, duration := as.numeric(difftime(
  max(recorded_dttm), min(recorded_dttm), units = "hours")
), by = .(hospitalization_id, run_id, med_category)]


# STEP 10: Remove duplicates to keep only one row per unique run
sedation_runs <- unique(meds_sedation_timeline_final, by = c("hospitalization_id", "run_id", "med_category"))


# STEP 11: Sum total time per medication within each hospitalization_id
sedation_duration_total <- sedation_runs[, .(total_hours = sum(duration)), by = .(hospitalization_id, med_category)]


# STEP 12: Identify the medication with the longest total duration as primary_sedative
# If the longest run has NA in 'total_hours', pick the next longest actual medication
sedation_primary <- sedation_duration_total[
  order(hospitalization_id, -total_hours),
  .SD[!is.na(total_hours)][1], 
  by = hospitalization_id
]

# Rename and clean up columns
setnames(sedation_primary, "med_category", "primary_sedative")

sedation_primary[is.na(primary_sedative), primary_sedative := "unknown"]


sedative_table <- sedation_primary[, .(hospitalization_id, primary_sedative)]
```



# PART EIGHT: Identify Hospital IDs for the hospitalizations in question using ADT Table
```{r}
# STEP 1: Clean ADT Table to retain only relevant hospitalizations
adt_clean <- adt[hospitalization_id %in% hosp_id_vitals_clean]
setorder(adt_clean, hospitalization_id, in_dttm)

# STEP 2: Merge with part_one_data_clean to bring in relevant hospital data
adt_clean_merge <- merge(adt_clean, part_one_data_clean, by = "hospitalization_id", all.x = TRUE)

# STEP 3: Replace blanks in 'hospital_id' with NA and use LOCF to fill forward values
adt_clean_merge[, hospital_id := fifelse(hospital_id == "", NA, hospital_id)]
adt_clean_merge[, hospital_id := na.locf(hospital_id, na.rm = FALSE), by = hospitalization_id]

# STEP 4: Identify consecutive runs of the same hospital_id within each hospitalization_id
adt_clean_merge[, `:=`(
  run_id = rleid(hospital_id),                     # Run ID for each consecutive block of the same hospital_id
  next_in_dttm = shift(in_dttm, type = "lead")     # Next 'in' time to define duration end
), by = hospitalization_id]

# STEP 5: Calculate duration of each run by finding the difference between the last and first in_dttm in each run
adt_clean_merge[, duration := as.numeric(difftime(
  max(in_dttm), min(in_dttm), units = "hours")
), by = .(hospitalization_id, run_id, hospital_id)]

# STEP 6: Remove duplicates to keep only one row per unique run
hospital_runs <- unique(adt_clean_merge, by = c("hospitalization_id", "run_id", "hospital_id"))

# STEP 7: Sum the total duration per hospital within each hospitalization_id
hospital_duration_total <- hospital_runs[, .(total_hours = sum(duration)), by = .(hospitalization_id, hospital_id)]

# STEP 8: Identify the hospital_id with the longest total duration, avoiding NA if possible
primary_hospital <- hospital_duration_total[
  order(hospitalization_id, -total_hours),
  .SD[!is.na(hospital_id)][1],            # Select the longest non-NA duration, if available
  by = hospitalization_id
]

# STEP 9: In case all durations are NA, this step fills those with NA in primary_hospital:
primary_hospital <- primary_hospital[
  , .SD[1], by = hospitalization_id]       # This will select the next longest, or NA if all are NA


# STEP 10: Replace any remaining NA values in hospital_id with "Unknown"
primary_hospital[is.na(hospital_id), hospital_id := "Unknown"]


hospital_id_final <- primary_hospital[, .(hospitalization_id, hospital_id)]
```


# PART NINE: Demographics Table
# ***Filter for demographic data for the identified hospitalization_ids
```{r}
# STEP 1: Determine Age at Admission
age_at_admission <- hospitalization[hospitalization_id %in% hosp_id_vitals_clean, .(patient_id, hospitalization_id, age_at_admission)]

pat_id_final <- unique(age_at_admission$patient_id)

# STEP 2: Pull patient information only for cleaned hospitalization_ids
patient_clean <- patient[patient_id %in% pat_id_final]

# STEP 3: Merge Patient and Age at Admission
demographics <- merge(age_at_admission, patient_clean, by = "patient_id", all.x = TRUE)
demographics <- demographics[, .(hospitalization_id, race_category, ethnicity_category, sex_category, language_name, age_at_admission)]

# STEP 4: Create language_category column
demographics[, language_category := fifelse(language_name == "English", "English",
                         fifelse(language_name == "Spanish", "Spanish",
                         fifelse(language_name %in% c("Other", "Unknown", "Patient Declined", "", "NA", "na", "n/a", "N/A"), "Unknown", 
                         "Other Language")))]
```


# PART TEN: 30-Day Mortality
# ***Identify patients who passed away in the 30 days after admission
```{r}
# STEP 1: Establish Admission DTTM
hosp_admission <- hospitalization[hospitalization_id %in% hosp_id_vitals_clean]
hosp_admission <- hosp_admission[, .(patient_id, hospitalization_id, admission_dttm)]

pat_id_admission <- unique(hosp_admission$patient_id)


# STEP 2: Establish Death DTTM
patient_death <- patient[patient_id %in% pat_id_admission]
patient_death <- patient_death[, .(patient_id, death_dttm)]

# STEP 3: Merge Admission and Death DTTM Tables
thirty_day_mortality <- merge(hosp_admission, patient_death, by = "patient_id", all.x = TRUE)

# STEP 4: Calculate Days Between Admission_DTTM and Death_DTTM
thirty_day_mortality[, days_to_death := as.numeric(difftime(death_dttm, admission_dttm, units = "days"))]

# STEP 5: Flag patients 30 days and under
thirty_day_mortality[, thirty_day_mortality := days_to_death <= 30]

# STEP 6: Clean up blank and NA values to "FALSE"
thirty_day_mortality[is.na(thirty_day_mortality) | thirty_day_mortality == "", thirty_day_mortality := FALSE]

# STEP 7: Reduce down table
thirty_day_mortality_final <- thirty_day_mortality[, .(hospitalization_id, thirty_day_mortality)]
```


# PART ELEVEN: Calculate SOFA Scores
```{r}
# Develop Data Tables Needed for SOFA Score Tabulation

# STEP 1: MAP Table
# Filter for SBP, DBP, and MAP values in vital_category
vitals_bp <- vitals[vital_category %in% c("sbp", "dbp", "map")][hospitalization_id %in% hosp_id_vitals_clean]

# Reshape the data to spread sbp, dbp, and map into separate columns, using 'mean' to handle duplicates
vitals_bp <- dcast(vitals_bp, 
                   hospitalization_id + recorded_dttm ~ vital_category, 
                   value.var = "vital_value", 
                   fun.aggregate = mean,  # Aggregate duplicates using mean
                   fill = NA)  # Fill missing values with NA
vitals_bp <- vitals_bp[, .(hospitalization_id, recorded_dttm, sbp, dbp)]
setorder(vitals_bp, hospitalization_id, recorded_dttm)

# Calculate MAP
vitals_bp[, map := (1/3 * sbp) + (2/3 * dbp)]

map_table <- vitals_bp[, .(hospitalization_id, recorded_dttm, map)]

# Merge with clean part one data table for time filtering
map_table_merge <- merge(part_one_data_clean, map_table, by = "hospitalization_id", all.x = TRUE)

#TIME FILTERING
# Calculate start_time (24 hours before begin_imv)
map_table_merge[, start_time := as.POSIXct(begin_imv) - hours(24), by = hospitalization_id]

# Calculate end_time based on the condition for each hospitalization_id
map_table_merge[, end_time := as.POSIXct(begin_imv), by = hospitalization_id]

# Filter the table to retain rows where recorded_dttm is within the time range
map_table_filt <- map_table_merge[recorded_dttm >= start_time & recorded_dttm <= end_time]
map_table_final <- map_table_filt[, .(hospitalization_id, recorded_dttm, map)]


# STEP 2: P/F Table
#FiO2 Values
resp_supp_fio2 <- respiratory_support[hospitalization_id %in% hosp_id_vitals_clean]
resp_supp_fio2 <- resp_supp_fio2[, .(hospitalization_id, recorded_dttm, fio2_set)]

#PaO2 Lab Values
labs_pao2 <- labs[lab_category %in% c("po2_arterial")][hospitalization_id %in% hosp_id_vitals_clean]
labs_pao2 <- labs_pao2[, .(hospitalization_id, recorded_dttm, lab_category, lab_value_numeric)]
setorder(labs_pao2, hospitalization_id, recorded_dttm)

# Reshape the data to spread pao2 into a column, using 'mean' to handle duplicates
labs_pao2 <- dcast(labs_pao2, 
                   hospitalization_id + recorded_dttm ~ lab_category, 
                   value.var = "lab_value_numeric", 
                   fun.aggregate = mean,  # Aggregate duplicates using mean
                   fill = NA)  # Fill missing values with NA
labs_pao2 <- labs_pao2[, .(hospitalization_id, recorded_dttm, po2_arterial)]


#Merge fio2 and clean part one data for time filtering
fio2_hosp_clean <- merge(part_one_data_clean, resp_supp_fio2, by = "hospitalization_id", all.x =TRUE)

#Merge pao2 and clean part one data for time filtering
pao2_hosp_clean <- merge(part_one_data_clean, labs_pao2, by = "hospitalization_id", all.x =TRUE)

#TIME FILTERING
# Calculate start_time (24 hours before begin_imv)
fio2_hosp_clean[, start_time := as.POSIXct(begin_imv) - hours(24), by = hospitalization_id]
pao2_hosp_clean[, start_time := as.POSIXct(begin_imv) - hours(24), by = hospitalization_id]

# Calculate end_time based on the condition for each hospitalization_id
fio2_hosp_clean[, end_time := as.POSIXct(begin_imv), by = hospitalization_id]
pao2_hosp_clean[, end_time := as.POSIXct(begin_imv), by = hospitalization_id]

# Filter the table to retain rows where recorded_dttm is within the time range
pao2_hosp_filt <- pao2_hosp_clean[recorded_dttm >= start_time & recorded_dttm <= end_time]
fio2_hosp_filt <- fio2_hosp_clean[recorded_dttm >= start_time & recorded_dttm <= end_time]
pao2_hosp_filt <- pao2_hosp_filt[, .(hospitalization_id, recorded_dttm, po2_arterial)]
fio2_hosp_filt <- fio2_hosp_filt[, .(hospitalization_id, recorded_dttm, fio2_set)]

# Merge
pao2_fio2_merge <- merge(fio2_hosp_filt, pao2_hosp_filt, 
                         by = c("hospitalization_id", "recorded_dttm"), 
                         all = TRUE)

#Use LOCF to Fill Out fio2 and po2_arterial columns
pao2_fio2_merge[fio2_set == "", fio2_set := NA]
pao2_fio2_merge[po2_arterial == "", po2_arterial := NA]
pao2_fio2_merge[, fio2_set := na.locf(fio2_set, na.rm = FALSE), by = hospitalization_id]
pao2_fio2_merge[, po2_arterial := na.locf(po2_arterial, na.rm = FALSE), by = hospitalization_id]

# Ensure fio2_set is numeric, converting non-numeric values to NA
pao2_fio2_merge[, fio2_set := as.numeric(fio2_set)]

# Calculate fio2_calc, dividing by 100 if fio2_set is greater than 1
pao2_fio2_merge[, fio2_calc := fifelse(fio2_set <= 1, fio2_set, fio2_set / 100)]

# Calculate P to F Ratio
pao2_fio2_merge[, p_to_f := po2_arterial / fio2_calc]
pao2_fio2_sofa <- pao2_fio2_merge[, .(hospitalization_id, recorded_dttm, p_to_f)]


# STEP 3: Creatinine Table
# Creatinine Lab Values
labs_cr <- labs[lab_category %in% c("creatinine")][hospitalization_id %in% hosp_id_vitals_clean]
labs_cr <- labs_cr[, .(hospitalization_id, recorded_dttm, lab_category, lab_value_numeric)]
setorder(labs_cr, hospitalization_id, recorded_dttm)

# Reshape the data to spread cr into a column, using 'mean' to handle duplicates
labs_cr <- dcast(labs_cr, 
                   hospitalization_id + recorded_dttm ~ lab_category, 
                   value.var = "lab_value_numeric", 
                   fun.aggregate = mean,  # Aggregate duplicates using mean
                   fill = NA)  # Fill missing values with NA
labs_cr <- labs_cr[, .(hospitalization_id, recorded_dttm, creatinine)]

#Merge cr and clean data from part one for time filtering
cr_hosp_clean <- merge(part_one_data_clean, labs_cr, by = "hospitalization_id", all.x =TRUE)

#TIME FILTERING
# Calculate start_time (24 hours before begin_imv)
cr_hosp_clean[, start_time := as.POSIXct(begin_imv) - hours(24), by = hospitalization_id]

# Calculate end_time based on the condition for each hospitalization_id
cr_hosp_clean[, end_time := as.POSIXct(begin_imv), by = hospitalization_id]

# Filter the table to retain rows where recorded_dttm is within the time range
cr_hosp_filt <- cr_hosp_clean[recorded_dttm >= start_time & recorded_dttm <= end_time]
cr_hosp_filt <- cr_hosp_filt[, .(hospitalization_id, recorded_dttm, creatinine)]


# STEP 4: Total Bilirubin Table
#Bilirubin Lab Values
labs_bili <- labs[lab_category %in% c("bilirubin_total")][hospitalization_id %in% hosp_id_vitals_clean]
labs_bili <- labs_bili[, .(hospitalization_id, recorded_dttm, lab_category, lab_value_numeric)]
setorder(labs_bili, hospitalization_id, recorded_dttm)

# Reshape the data to spread bili into a column, using 'mean' to handle duplicates
labs_bili <- dcast(labs_bili, 
                   hospitalization_id + recorded_dttm ~ lab_category, 
                   value.var = "lab_value_numeric", 
                   fun.aggregate = mean,  # Aggregate duplicates using mean
                   fill = NA)  # Fill missing values with NA
labs_bili <- labs_bili[, .(hospitalization_id, recorded_dttm, bilirubin_total)]

#Merge bili and clean part one data table for time filtering
bili_hosp_clean <- merge(part_one_data_clean, labs_bili, by = "hospitalization_id", all.x =TRUE)

#TIME FILTERING
# Calculate start_time (24 hours before begin_imv)
bili_hosp_clean[, start_time := as.POSIXct(begin_imv) - hours(24), by = hospitalization_id]

# Calculate end_time based on the condition for each hospitalization_id
bili_hosp_clean[, end_time := as.POSIXct(begin_imv), by = hospitalization_id]

# Filter the table to retain rows where recorded_dttm is within the time range
bili_hosp_filt <- bili_hosp_clean[recorded_dttm >= start_time & recorded_dttm <= end_time]
bili_hosp_filt <- bili_hosp_filt[, .(hospitalization_id, recorded_dttm, bilirubin_total)]


# STEP 5: Platelets Table
#Platelet Lab Values
labs_platelets <- labs[lab_category %in% c("platelet_count")][hospitalization_id %in% hosp_id_vitals_clean]
labs_platelets <- labs_platelets[, .(hospitalization_id, recorded_dttm, lab_category, lab_value_numeric)]
setorder(labs_platelets, hospitalization_id, recorded_dttm)

# Reshape the data to spread plts into a column, using 'mean' to handle duplicates
labs_platelets <- dcast(labs_platelets, 
                   hospitalization_id + recorded_dttm ~ lab_category, 
                   value.var = "lab_value_numeric", 
                   fun.aggregate = mean,  # Aggregate duplicates using mean
                   fill = NA)  # Fill missing values with NA
labs_platelets <- labs_platelets[, .(hospitalization_id, recorded_dttm, platelet_count)]

#Merge plts and clean data from part one for time filtering
platelets_hosp_clean <- merge(part_one_data_clean, labs_platelets, by = "hospitalization_id", all.x =TRUE)

#TIME FILTERING
# Calculate start_time (24 hours before begin_imv)
platelets_hosp_clean[, start_time := as.POSIXct(begin_imv) - hours(24), by = hospitalization_id]

# Calculate end_time based on the condition for each hospitalization_id
platelets_hosp_clean[, end_time := as.POSIXct(begin_imv), by = hospitalization_id]

# Filter the table to retain rows where recorded_dttm is within the time range
platelets_hosp_filt <- platelets_hosp_clean[recorded_dttm >= start_time & recorded_dttm <= end_time]
platelets_hosp_filt <- platelets_hosp_filt[, .(hospitalization_id, recorded_dttm, platelet_count)]



# STEP 6: GCS Table
# Identify GCS_Total Values
pat_assess_gcs <- patient_assessments[assessment_category == "gcs_total"][hospitalization_id %in% hosp_id_vitals_clean]
setorder(pat_assess_gcs, hospitalization_id, recorded_dttm)
pat_assess_gcs[numerical_value == "", numerical_value := NA]
pat_assess_gcs[, numerical_value := as.numeric(numerical_value)]


# Reshape the data to spread GCS into a column, using 'mean' to handle duplicates
pat_assess_gcs_clean <- dcast(
    pat_assess_gcs, 
    hospitalization_id + recorded_dttm ~ assessment_category, 
    value.var = "numerical_value", 
    fun.aggregate = function(x) mean(x, na.rm = TRUE),  # Aggregate with NA handling
    fill = NA
)
pat_assess_gcs_clean <- pat_assess_gcs_clean[, .(hospitalization_id, recorded_dttm, gcs_total)]

# Merge GCS data with clean data from part one for time filtering
gcs_hosp_clean <- merge(part_one_data_clean, pat_assess_gcs_clean, by = "hospitalization_id", all.x = TRUE)

#TIME FILTERING
# Calculate start_time (24 hours before begin_imv)
gcs_hosp_clean[, start_time := as.POSIXct(begin_imv) - hours(24), by = hospitalization_id]

# Calculate end_time based on the condition for each hospitalization_id
gcs_hosp_clean[, end_time := as.POSIXct(begin_imv), by = hospitalization_id]

# Filter the table to retain rows where recorded_dttm is within the time range
gcs_hosp_filt <- gcs_hosp_clean[recorded_dttm >= start_time & recorded_dttm <= end_time]
gcs_hosp_filt <- gcs_hosp_filt[, .(hospitalization_id, recorded_dttm, gcs_total)]


# STEP 7: SOFA Meds
# Filter only for vasopressor sofa meds
meds_sofa <- meds[med_category %in% c("dopamine", "dobutamine", "epinephrine", "norepineprhine")][hospitalization_id %in% hosp_id_vitals_clean]
meds_sofa <- meds_sofa[, .(hospitalization_id, admin_dttm, med_category, med_dose, med_dose_unit)]
setnames(meds_sofa, "admin_dttm", "recorded_dttm")
setorder(meds_sofa, hospitalization_id, recorded_dttm)

# Merge with Weight Data
meds_sofa_weight <- merge(meds_sofa, admission_bmi, by = "hospitalization_id", all.x = TRUE)
meds_sofa_weight <- meds_sofa_weight[, .(hospitalization_id, recorded_dttm, med_category, med_dose, med_dose_unit, admission_weight)]

# Ensure med_dose and admission_weight are numeric, converting non-numeric values to NA
meds_sofa_weight[, med_dose := as.numeric(med_dose)]
meds_sofa_weight[, admission_weight := as.numeric(admission_weight)]

# Calculate med_dose_weight with the updated numeric columns
meds_sofa_weight[, med_dose_weight := fifelse(
  med_dose_unit %in% c("mcg/kg/min", "MCG/KG/MIN", "Mcg/Kg/Min"), 
  med_dose, 
  med_dose / admission_weight
)]
meds_sofa_weight_clean <- meds_sofa_weight[, .(hospitalization_id, recorded_dttm, med_category, med_dose_weight)]

# Merge SOFA Meds with cleaned part one data for time filtering
meds_sofa_hosp_clean <- merge(part_one_data_clean, meds_sofa_weight_clean, by = "hospitalization_id", all.x = TRUE)

#TIME FILTERING
# Calculate start_time (24 hours before begin_imv)
meds_sofa_hosp_clean[, start_time := as.POSIXct(begin_imv) - hours(24), by = hospitalization_id]

# Calculate end_time based on the condition for each hospitalization_id
meds_sofa_hosp_clean[, end_time := as.POSIXct(begin_imv), by = hospitalization_id]

# Filter the table to retain rows where recorded_dttm is within the time range
meds_sofa_hosp_filt <- meds_sofa_hosp_clean[recorded_dttm >= start_time & recorded_dttm <= end_time]
meds_sofa_hosp_filt <- meds_sofa_hosp_filt[, .(hospitalization_id, recorded_dttm, med_category, med_dose_weight)]


# ******
# STEP 8: MERGER of data tables to form final SOFA Table
# *****

# First Merge Timeline with P/F
sofa_table_one <- merge(hosp_clean_timeline, pao2_fio2_sofa, 
                         by = c("hospitalization_id", "recorded_dttm"), 
                         all = TRUE)

# Second Merge with Platelets
sofa_table_two <- merge(sofa_table_one, platelets_hosp_filt, 
                         by = c("hospitalization_id", "recorded_dttm"), 
                         all = TRUE)

# Third Merge with GCS
sofa_table_three <- merge(sofa_table_two, gcs_hosp_filt, 
                         by = c("hospitalization_id", "recorded_dttm"), 
                         all = TRUE)

# Fourth Merge with Bilirubin
sofa_table_four <- merge(sofa_table_three, bili_hosp_filt, 
                         by = c("hospitalization_id", "recorded_dttm"), 
                         all = TRUE)

# Fifth Merge with Creatinine
sofa_table_five <- merge(sofa_table_four, cr_hosp_filt, 
                         by = c("hospitalization_id", "recorded_dttm"), 
                         all = TRUE)

# Sixth Merge with MAP
sofa_table_six <- merge(sofa_table_five, map_table_final, 
                         by = c("hospitalization_id", "recorded_dttm"), 
                         all = TRUE)

# Final Merge with SOFA Meds
sofa_table_final <- merge(sofa_table_six, meds_sofa_hosp_filt, 
                         by = c("hospitalization_id", "recorded_dttm"), 
                         all = TRUE)

# Fill in Blanks and Use LOCF to Fill Out the Table
cols_to_update <- c("p_to_f", "platelet_count", "gcs_total", "bilirubin_total", "creatinine", "map", "med_category", "med_dose_weight")
sofa_table_final[, (cols_to_update) := lapply(.SD, function(x) fifelse(x == "", NA, x)), .SDcols = cols_to_update]

sofa_table <- sofa_table_final[, (cols_to_update) := lapply(.SD, function(x) na.locf(x, na.rm = FALSE)), 
                 by = hospitalization_id, .SDcols = cols_to_update]


# STEP 9: SOFA SCORE ASSEMBLY

# Pulm SOFA
sofa_table[, pulm_sofa := fcase(
  p_to_f >= 400, 0,
  p_to_f >= 300 & p_to_f < 400, 1,
  p_to_f >= 200 & p_to_f < 300, 2,
  p_to_f >= 100 & p_to_f < 200, 3,
  p_to_f < 100, 4,
  is.na(p_to_f), 0  # Assign 0 if p_to_f is NA
)]

# Heme SOFA
sofa_table[, heme_sofa := fcase(
  platelet_count >= 150, 0,
  platelet_count >= 100 & platelet_count < 150, 1,
  platelet_count >= 50 & platelet_count < 100, 2,
  platelet_count >= 20 & platelet_count < 50, 3,
  platelet_count < 20, 4,
  is.na(platelet_count), 0  # Assign 0 if platelet_count is NA
)]

# Neuro SOFA
sofa_table[, neuro_sofa := fcase(
  gcs_total == 15, 0,
  gcs_total >= 13 & gcs_total < 15, 1,
  gcs_total >= 10 & gcs_total < 13, 2,
  gcs_total >= 6 & gcs_total < 10, 3,
  gcs_total < 6, 4,
  is.na(gcs_total), 0  # Assign 0 if gcs_total is NA
)]

# GI SOFA
sofa_table[, gi_sofa := fcase(
  bilirubin_total < 1.2, 0,
  bilirubin_total >= 1.2 & bilirubin_total < 2.0, 1,
  bilirubin_total >= 2.0 & bilirubin_total < 6.0, 2,
  bilirubin_total >= 6.0 & bilirubin_total < 12.0, 3,
  bilirubin_total >= 12, 4,
  is.na(bilirubin_total), 0  # Assign 0 if bilirubin_total is NA
)]

# Renal SOFA
sofa_table[, renal_sofa := fcase(
  creatinine < 1.2, 0,
  creatinine >= 1.2 & creatinine < 2.0, 1,
  creatinine >= 2.0 & creatinine < 3.5, 2,
  creatinine >= 3.5 & creatinine < 5.0, 3,
  creatinine >= 5.0, 4,
  is.na(creatinine), 0  # Assign 0 if creatinine is NA
)]

# Card SOFA
sofa_table[, card_sofa := fcase(
  map > 70 & is.na(med_category), 0,
  map < 70 & is.na(med_category), 1,
  med_category == "dopamine" & med_dose_weight <= 5, 2,
  med_category == "dobutamine", 2,
  med_category == "dopamine" & med_dose_weight > 5, 3,
  med_category == "epinephrine" & med_dose_weight <= 0.1, 3,
  med_category == "norepinephrine" & med_dose_weight <= 0.1, 3,
  med_category == "dopamine" & med_dose_weight >= 15, 4,
  med_category == "epinephrine" & med_dose_weight > 0.1, 4,
  med_category == "norepinephrine" & med_dose_weight > 0.1, 4,
  is.na(map) | is.na(med_category) | is.na(med_dose_weight), 0  # Assign 0 if any relevant value is NA
)]


# STEP 10: List of SOFA score columns for which to calculate maximum value
sofa_cols <- c("pulm_sofa", "heme_sofa", "neuro_sofa", "gi_sofa", "renal_sofa", "card_sofa")


# STEP 11: Create a new table with the maximum SOFA scores per hospitalization_id
max_sofa_table <- sofa_table[, lapply(.SD, max, na.rm = TRUE), by = hospitalization_id, .SDcols = sofa_cols]


# STEP 12: Calculate total SOFA score
max_sofa_table[, total_sofa := pulm_sofa + heme_sofa + neuro_sofa + gi_sofa + renal_sofa + card_sofa]
sofa_final <- max_sofa_table[, .(hospitalization_id, total_sofa)] 
```


# PART TWELVE: Assemble Final Analytic Table
# ***Merge all tables
```{R}
# First Merge Demographics and RASS Percent
analytic_table_one <- merge(demographics, rass_percentages, by = "hospitalization_id", all.x = TRUE)
setnames(analytic_table_one, 
         old = c("race_category", "ethnicity_category", "sex_category", "language_category", "age_at_admission"), 
         new = c("race", "ethnicity", "sex", "language", "age"))

# Second Merge with BMI
analytic_table_two <- merge(analytic_table_one, admission_bmi_final, by = "hospitalization_id", all.x = TRUE)

# Third merge with Paralysis
analytic_table_three <- merge(analytic_table_two, paralytic_final, by = "hospitalization_id", all.x = TRUE)

# Fourth Merge with SOFA
analytic_table_four <- merge(analytic_table_three, sofa_final, by = "hospitalization_id", all.x = TRUE)

# Fifth Merge with Hospital ID
analytic_table_five <- merge(analytic_table_four, hospital_id_final, by = "hospitalization_id", all.x = TRUE)

# Sixth Merge with Sedative Table
analytic_table_six <- merge(analytic_table_five, sedative_table, by = "hospitalization_id", all.x =TRUE)

# Seventh Merge with 30-Day Mortality Data
analytic_table_seven <- merge(analytic_table_six, thirty_day_mortality_final, by = "hospitalization_id", all.x =TRUE)

# Eighth Merge with Part One Data
analytic_table_eight <- merge(analytic_table_seven, part_one_data_clean, by = "hospitalization_id", all.x =TRUE)

# Select only for pertinent columns
analytic_table_final <- analytic_table_eight[, .(hospitalization_id, race, ethnicity, sex, age, language, percent_deep_sedation, bmi, paralyzed, total_sofa, hospital_id, primary_sedative, thirty_day_mortality, total_imv_time)] 


#Save to file
fwrite(analytic_table_final, file = paste0(output_dir, "analytic_table.csv.gz"))
```

